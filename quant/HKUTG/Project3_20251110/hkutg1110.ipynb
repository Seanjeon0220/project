{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80ae2053",
      "metadata": {
        "id": "80ae2053"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31c2775e",
      "metadata": {
        "id": "31c2775e"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5dbd36a4",
      "metadata": {
        "id": "5dbd36a4"
      },
      "source": [
        "# Pricing Bermudan (American-ish) Options via Least–Squares Monte Carlo\n",
        "\n",
        "This document describes in detail how to implement the **Longstaff–Schwartz** (2001) algorithm for pricing a Bermudan option (a discretely exercisable American option) using Python. We will:\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Problem Setup\n",
        "\n",
        "- We have exercise dates  \n",
        "  $$\n",
        "    0 = t_0 < t_1 < t_2 < \\cdots < t_N = T\\,.\n",
        "  $$\n",
        "- On each date $t_i$ the (undiscounted) payoff of immediate exercise is  \n",
        "  $$\n",
        "    F_{t_i} = h\\bigl(S_{t_i}\\bigr),\n",
        "  $$\n",
        "  e.g.\\ for a put option $h(S) = \\max(K - S,0)$.\n",
        "- We work under the risk-neutral measure $\\mathbb{Q}$. Let  \n",
        "  $$\n",
        "    D_{t_i,t_j} = \\exp\\bigl(-\\!\\int_{t_i}^{t_j} r(s)\\,ds \\bigr)\n",
        "  $$\n",
        "  be the stochastic discount factor.\n",
        "\n",
        "The continuation value at time $t_i$ is\n",
        "$$\n",
        "  C_{t_i} \\;=\\;\n",
        "  \\mathbb{E}^\\mathbb{Q}\\bigl[D_{t_i,t_{i+1}}\\,V_{t_{i+1}}\\mid \\mathcal{F}_{t_i}\\bigr],\n",
        "$$\n",
        "(note that we wish to find a good regression for the estimate of this continuation value) where\n",
        "$$\n",
        "  V_{t_{i+1}} \\;=\\; \\max\\bigl(F_{t_{i+1}},\\,C_{t_{i+1}}\\bigr).\n",
        "$$\n",
        "The Longstaff–Schwartz algorithm replaces this conditional expectation by a least-squares regression on simulated paths.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Longstaff–Schwartz Algorithm (Backward Induction)\n",
        "\n",
        "1. **Simulate** $M$ paths of the underlying price $S_{t_i}^{(m)}$, $i=0,\\dots,N$, under $\\mathbb{Q}$.  \n",
        "2. **Initialize** cash-flows at maturity:  \n",
        "   $$\n",
        "     X_{t_N}^{(m)} = F_{t_N}^{(m)},\\quad m=1,\\dots,M.\n",
        "   $$\n",
        "3. **Backward induction** for $i = N-1,\\,N-2,\\,\\dots,1$:\n",
        "   a. For each path $m$, collect the in-the-money subset $\\{m : F_{t_i}^{(m)}>0\\}$.  \n",
        "   b. Regress the *discounted* continuation values  \n",
        "      $$\n",
        "        Y^{(m)} = D_{t_i,t_{i+1}}\\;X_{t_{i+1}}^{(m)}\n",
        "      $$\n",
        "      against basis functions of the state $S_{t_i}^{(m)}$, e.g.\\ polynomials $\\{1,\\,S,\\,S^2\\}$.  \n",
        "   c. Denote the fitted regression by $\\widehat C_{t_i}(S)$.  \n",
        "   d. **Exercise decision**:  \n",
        "      $$\n",
        "        X_{t_i}^{(m)}\n",
        "        =\n",
        "        \\begin{cases}\n",
        "          F_{t_i}^{(m)}, &\\text{if }F_{t_i}^{(m)} \\ge \\widehat C_{t_i}\\bigl(S_{t_i}^{(m)}\\bigr),\\\\[6pt]\n",
        "          D_{t_i,t_{i+1}}\\;X_{t_{i+1}}^{(m)}, &\\text{otherwise.}\n",
        "        \\end{cases}\n",
        "      $$\n",
        "4. **Price** at $t=0$ is estimated by the discounted expectation of $X_{t_1}$:\n",
        "   $$\n",
        "     \\widehat V_0\n",
        "     = \\frac{1}{M}\\sum_{m=1}^M D_{0,t_1}\\;X_{t_1}^{(m)}.\n",
        "   $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71f35ded",
      "metadata": {
        "id": "71f35ded"
      },
      "outputs": [],
      "source": [
        "def blackscholes_mc(ts, n_paths, S0, vol, r, q):\n",
        "    \"\"\"Generate Monte-Carlo paths in Black-Scholes model.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    ts: array_like\n",
        "        The time steps of the simualtion\n",
        "    n_paths: int\n",
        "        the number of paths to simulate\n",
        "    S0: scalar\n",
        "        The spot price of the underlying security.\n",
        "    vol: scalar\n",
        "        The implied Black-Scholes volatility.\n",
        "    r: scalar\n",
        "        The annualized risk-free interest rate, continuously compounded.\n",
        "    q: scalar\n",
        "        The annualized continuous dividend yield.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    paths: ndarray\n",
        "        The Monte-Carlo paths.\n",
        "    \"\"\"\n",
        "    paths = np.full((len(ts), n_paths), np.nan, dtype=float)\n",
        "    paths[0] = S0\n",
        "    for i in range(len(ts)-1):\n",
        "        dt = ts[i+1] - ts[i]\n",
        "        dW = np.sqrt(dt)*np.random.randn(n_paths)\n",
        "        paths[i+1] = paths[i] * np.exp((r-q-1/2*vol**2)*dt + vol*dW)\n",
        "    return paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "437809c3",
      "metadata": {
        "id": "437809c3"
      },
      "outputs": [],
      "source": [
        "S0 = 100\n",
        "vol = 0.2\n",
        "r = 0.1\n",
        "q = 0.02\n",
        "K = 100\n",
        "T = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2493e3f4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "2493e3f4",
        "outputId": "6a588845-a972-4bf1-a6b5-7d81c9ca5e4e"
      },
      "outputs": [],
      "source": [
        "ts = np.linspace(0, 1, 13)\n",
        "n_paths = 10000\n",
        "paths = blackscholes_mc(ts, n_paths, S0, vol, r, q) # generates Monte Carlo Paths for the stock price\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "ax.plot(ts, paths[:, :25], lw=1)\n",
        "ax.set_xticks(ts)\n",
        "ax.set_xticklabels(['0', '1M', '2M', '3M', '4M', '5M', '6M', '7M', '8M', '9M', '10M', '11M', '1Y'])\n",
        "ax.set_ylabel('Stock Price')\n",
        "ax.grid(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26df4d28",
      "metadata": {
        "id": "26df4d28"
      },
      "source": [
        "### Price of European put option"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a15df7f1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a15df7f1",
        "outputId": "2352c431-df7d-4dda-ee5d-5c92a9d11c60"
      },
      "outputs": [],
      "source": [
        "np.mean(np.maximum(K-paths[-1], 0))*np.exp(-r*T)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "615ead7c",
      "metadata": {
        "id": "615ead7c"
      },
      "source": [
        "#### Longstaff-Schwartz algorithm\n",
        "\n",
        "We use polynomials as basis functions for demonstration purposes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "332ffcce",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "332ffcce",
        "outputId": "d38d16d7-898f-4abb-87cf-2132e0279c98"
      },
      "outputs": [],
      "source": [
        "payoff = np.maximum(K-paths[-1], 0)\n",
        "for i in range(len(ts)-2, 0, -1):\n",
        "    discount = np.exp(-r*(ts[i+1]-ts[i]))\n",
        "    payoff = payoff*discount\n",
        "\n",
        "    # THE REGRESSION IS DONE HERE -- here, we are simply using polynomial regression\n",
        "    # (recall the other methods from ConditionalExpectation.ipynb)\n",
        "    p = np.polyfit(paths[i], payoff, deg=2)\n",
        "    contval = np.polyval(p, paths[i])\n",
        "    exerval = np.maximum(K-paths[i], 0)\n",
        "    # identify the paths where we should exercise\n",
        "    ind = exerval > contval\n",
        "    payoff[ind] = exerval[ind]\n",
        "np.mean(payoff*np.exp(-r*(ts[1]-ts[0])))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4e89abc",
      "metadata": {
        "id": "f4e89abc"
      },
      "source": [
        "For your reference, the price of the Bermudan option is $5.152$. In the exercise below, try to see if you can get close to this value (will be helpful for our project later on)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4728971",
      "metadata": {
        "id": "a4728971"
      },
      "source": [
        "# **Longstaff–Schwartz** Regression Method\n",
        "\n",
        "We now adapt both the **Longstaff–Schwartz** (LS) algorithm to use three different regression methods:\n",
        "\n",
        "  1. **Black–Scholes basis**: $\\{1,\\;P_{\\rm BS}(S_{t},K,r,\\bar\\sigma,\\tau)\\}$  \n",
        "     where $P_{\\rm BS}$ is the European‐put formula with volatility $\\bar\\sigma=0.2$ and remaining time $\\tau=T-t$.  \n",
        "  2. **Piecewise‐linear regression** with $J$ knots. (Try different values of $J$)\n",
        "  3. **Kernel (Nadaraya–Watson)** regression with a Gaussian kernel and bandwidth $h$. (Try different values of $h$).\n",
        "\n",
        "We first set up our simulation and then define:\n",
        "- A **Black–Scholes European Pricer** function (GIVEN BELOW),\n",
        "- (**Task 1**) A **pricers** (`ls_pricer`) that estimates the CONTINUATION VALUE to decide whether or not you will exercise on a certain date."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd5b050d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd5b050d",
        "outputId": "306ffac9-109d-4b18-ca6a-24639563fdd4"
      },
      "outputs": [],
      "source": [
        "def blackscholes_price(K, T, S0, vol, r=0, q=0, callput='call'):\n",
        "    \"\"\"Compute the call/put option price in the Black-Scholes model\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    K: scalar or array_like\n",
        "        The strike of the option.\n",
        "    T: scalar or array_like\n",
        "        The maturity of the option, expressed in years (e.g. 0.25 for 3-month and 2 for 2 years)\n",
        "    S0: scalar or array_like\n",
        "        The current price of the underlying asset.\n",
        "    vol: scalar or array_like\n",
        "        The implied Black-Scholes volatility.\n",
        "    r: scalar or array_like\n",
        "        The annualized risk-free interest rate, continuously compounded.\n",
        "    q: scalar or array_like\n",
        "        The annualized continuous dividend yield.\n",
        "    callput: str\n",
        "        Must be either 'call' or 'put'.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    price: scalar or array_like\n",
        "        The price of the option.\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    >>> blackscholes_price(95, 0.25, 100, 0.2, r=0.05, callput='put')\n",
        "    1.5342604771222823\n",
        "    \"\"\"\n",
        "    F = S0*np.exp((r-q)*T)\n",
        "    v = vol*np.sqrt(T)\n",
        "    d1 = np.log(F/K)/v + 0.5*v\n",
        "    d2 = d1 - v\n",
        "    try:\n",
        "        opttype = {'call':1, 'put':-1}[callput.lower()]\n",
        "    except:\n",
        "        raise ValueError('The value of callput must be either \"call\" or \"put\".')\n",
        "    price = opttype*(F*norm.cdf(opttype*d1)-K*norm.cdf(opttype*d2))*np.exp(-r*T)\n",
        "    return price\n",
        "\n",
        "blackscholes_price(95, 0.25, 100, 0.2, r=0.05, callput='put')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53c736c9",
      "metadata": {
        "id": "53c736c9"
      },
      "source": [
        "The Longstaff-Schwartz algorithm provide an estimate for the expected payoff from continuation at each exercise date from the cross-sectional information in the simulation using regression. By comparing this estimate with the immediate exercise value, the holder of the option can determine whether to exercise the option or continue.\n",
        "\n",
        "**(Task 2)** Perform an independent Monte Carlo simulation using this estimate of continuation value from LS algorithm as an exercise policy, and estimate the price of the American put. Explain why this estimate is a lower bound. Try different methods for regression and compare the results.\n",
        "\n",
        "Show your code and result with at least 100000 simulations."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "FhTH2hAxP3cZ",
      "metadata": {
        "id": "FhTH2hAxP3cZ"
      },
      "source": [
        "# Task 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "feYwL34zP3GP",
      "metadata": {
        "id": "feYwL34zP3GP"
      },
      "outputs": [],
      "source": [
        "# regression: polynomial\n",
        "\n",
        "def regression_polynomial(X, Y, S_current, degree=3, **kwargs):\n",
        "\n",
        "    coeffs = np.polyfit(X, Y, deg=degree)\n",
        "    cont_value = np.polyval(coeffs, S_current)\n",
        "    model = {\n",
        "        'type': 'polynomial',\n",
        "        'coeffs': coeffs,\n",
        "        'degree': degree\n",
        "    }\n",
        "\n",
        "    return cont_value, model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VOHG1YIKRlpU",
      "metadata": {
        "id": "VOHG1YIKRlpU"
      },
      "outputs": [],
      "source": [
        "# regression: bs\n",
        "\n",
        "def regression_bs_basis(X, Y, S_current, K, r, tau, vol=0.2, q=0, **kwargs):\n",
        "    Z_train = blackscholes_price(K, tau, X, vol, r, q, callput='put')\n",
        "\n",
        "    A = np.vstack([np.ones(len(Z_train)), Z_train]).T\n",
        "    beta = np.linalg.lstsq(A, Y, rcond=None)[0]\n",
        "\n",
        "    Z_current = blackscholes_price(K, tau, S_current, vol, r, q, callput='put')\n",
        "    cont_value = beta[0] + beta[1] * Z_current\n",
        "\n",
        "    model = {\n",
        "        'type': 'bs_basis',\n",
        "        'beta': beta,\n",
        "        'vol': vol,\n",
        "        'q': q,\n",
        "        'tau': tau\n",
        "    }\n",
        "\n",
        "    return cont_value, model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bl2IxO-jVHJg",
      "metadata": {
        "id": "bl2IxO-jVHJg"
      },
      "outputs": [],
      "source": [
        "# regression: piecewise\n",
        "\n",
        "def regression_piecewise(X, Y, S_current, n_knots=10, **kwargs):\n",
        "    knots = np.percentile(X, np.linspace(0, 100, n_knots+1))\n",
        "\n",
        "    segment = np.searchsorted(knots, S_current) - 1\n",
        "    segment = np.clip(segment, 0, n_knots-1)\n",
        "\n",
        "    cont_value = np.zeros_like(S_current, dtype=float)\n",
        "    coeffs_list = []\n",
        "\n",
        "    for i in range(n_knots):\n",
        "        mask = (X >= knots[i]) & (X < knots[i+1])\n",
        "        if i == n_knots-1:\n",
        "            mask = (X >= knots[i]) & (X <= knots[i+1])\n",
        "\n",
        "        if np.sum(mask) >= 2:\n",
        "            X_seg = X[mask]\n",
        "            Y_seg = Y[mask]\n",
        "            coeffs = np.polyfit(X_seg, Y_seg, deg=1)\n",
        "            coeffs_list.append(coeffs)\n",
        "\n",
        "            current_mask = segment == i\n",
        "            cont_value[current_mask] = np.polyval(coeffs, S_current[current_mask])\n",
        "        else:\n",
        "            coeffs_list.append(None)\n",
        "\n",
        "    model = {\n",
        "        'type': 'piecewise',\n",
        "        'knots': knots,\n",
        "        'coeffs_list': coeffs_list,\n",
        "        'n_knots': n_knots\n",
        "    }\n",
        "\n",
        "    return cont_value, model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Xp3t0_aRVJda",
      "metadata": {
        "id": "Xp3t0_aRVJda"
      },
      "outputs": [],
      "source": [
        "# regression: kernel\n",
        "\n",
        "def regression_kernel(X, Y, S_current, bandwidth=10, **kwargs):\n",
        "    distances = S_current[:, np.newaxis] - X[np.newaxis, :]\n",
        "\n",
        "    weights = np.exp(-0.5 * (distances / bandwidth)**2)\n",
        "    weights /= weights.sum(axis=1, keepdims=True)\n",
        "\n",
        "    cont_value = weights @ Y\n",
        "\n",
        "    model = {\n",
        "        'type': 'kernel',\n",
        "        'bandwidth': bandwidth,\n",
        "        'X': X,\n",
        "        'Y': Y\n",
        "    }\n",
        "\n",
        "    return cont_value, model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9I7-LCQqXEas",
      "metadata": {
        "id": "9I7-LCQqXEas"
      },
      "outputs": [],
      "source": [
        "# ls_pricer\n",
        "\n",
        "def ls_pricer(paths, K, r, ts, regression_func, **regression_params):\n",
        "    n_steps, n_paths = paths.shape\n",
        "    payoff = np.maximum(K - paths[-1], 0)\n",
        "\n",
        "    exercise_policy = {\n",
        "        'models': [],\n",
        "        'ts': ts,\n",
        "        'K': K,\n",
        "        'r': r,\n",
        "        'regression_func': regression_func,\n",
        "        'regression_params': regression_params\n",
        "    }\n",
        "\n",
        "    for i in range(n_steps-2, 0, -1):\n",
        "        discount = np.exp(-r * (ts[i+1] - ts[i]))\n",
        "        payoff_discounted = payoff * discount\n",
        "\n",
        "        exercise_value = np.maximum(K - paths[i], 0)\n",
        "\n",
        "        X = paths[i]\n",
        "        Y = payoff_discounted\n",
        "        tau = ts[-1] - ts[i]\n",
        "\n",
        "        cont_value, model = regression_func(\n",
        "            X, Y, X,\n",
        "            K=K, r=r, tau=tau,\n",
        "            **regression_params\n",
        "        )\n",
        "\n",
        "        exercise_policy['models'].insert(0, model)\n",
        "\n",
        "        exercise_mask = exercise_value > cont_value\n",
        "\n",
        "        payoff_new = payoff_discounted.copy()\n",
        "        payoff_new[exercise_mask] = exercise_value[exercise_mask]\n",
        "        payoff = payoff_new\n",
        "\n",
        "    price = np.mean(payoff * np.exp(-r * (ts[1] - ts[0])))\n",
        "\n",
        "    return price, exercise_policy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dYJfhlHG57OC",
      "metadata": {
        "id": "dYJfhlHG57OC"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "ts = np.linspace(0, T, 13)\n",
        "paths = blackscholes_mc(ts, 2000, S0, vol, r, q)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nJtiJ3AOZthk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJtiJ3AOZthk",
        "outputId": "b59883df-5dce-49ef-e84a-6c1d97cf098a"
      },
      "outputs": [],
      "source": [
        "# piecewise - tuning\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"PIECEWISE LINEAR REGRESSION - PARAMETER TUNING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "results_pw = []\n",
        "for n_knots in [3, 4, 5, 6, 7, 10, 20, 30, 40, 50]:\n",
        "    price, _ = ls_pricer(\n",
        "        paths, K, r, ts,\n",
        "        regression_func=regression_piecewise,\n",
        "        n_knots=n_knots\n",
        "    )\n",
        "    error = abs(price - 5.152)\n",
        "    results_pw.append({\n",
        "        'n_knots': n_knots,\n",
        "        'Price': price,\n",
        "        'Error': error\n",
        "    })\n",
        "    print(f\"n_knots={n_knots:2d}  |  Price: {price:.4f}  |  Error: {error:.4f}\")\n",
        "\n",
        "print(f\"\\nReference price: 5.152\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gJTkLMRJaAuw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJTkLMRJaAuw",
        "outputId": "57277b6c-afa3-4cbc-a7d1-273797a0c4a4"
      },
      "outputs": [],
      "source": [
        "# krenel - tuning\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"KERNEL REGRESSION - PARAMETER TUNING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "results_kr = []\n",
        "for h in [2, 3, 5, 10, 20, 50]:\n",
        "    price, _ = ls_pricer(\n",
        "        paths, K, r, ts,\n",
        "        regression_func=regression_kernel,\n",
        "        bandwidth=h\n",
        "    )\n",
        "    error = abs(price - 5.152)\n",
        "    results_kr.append({\n",
        "        'bandwidth': h,\n",
        "        'Price': price,\n",
        "        'Error': error\n",
        "    })\n",
        "    print(f\"bandwidth={h:2d}  |  Price: {price:.4f}  |  Error: {error:.4f}\")\n",
        "\n",
        "print(f\"\\nReference price: 5.152\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1yjZ09_-3IUc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yjZ09_-3IUc",
        "outputId": "ad28dce2-a3d3-47f2-ab0e-ff685ec1cc69"
      },
      "outputs": [],
      "source": [
        "# result for task1\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"FINAL COMPARISON WITH OPTIMAL PARAMETERS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "price_poly, policy_poly = ls_pricer(paths, K, r, ts, regression_polynomial)\n",
        "price_bs, policy_bs = ls_pricer(paths, K, r, ts, regression_bs_basis, vol=0.2)\n",
        "\n",
        "best_pw = min(results_pw, key=lambda x: x['Error'])\n",
        "best_kr = min(results_kr, key=lambda x: x['Error'])\n",
        "\n",
        "print(f\"\\nBest parameters found:\")\n",
        "print(f\"  Piecewise: n_knots={best_pw['n_knots']} (error: {best_pw['Error']:.4f})\")\n",
        "print(f\"  Kernel: bandwidth={best_kr['bandwidth']} (error: {best_kr['Error']:.4f})\")\n",
        "\n",
        "print(f\"\\nFinal prices with optimal parameters:\")\n",
        "print(f\"  Polynomial (deg=3)       : {price_poly:.4f}\")\n",
        "print(f\"  BS Basis (vol=0.2)       : {price_bs:.4f}\")\n",
        "print(f\"  Piecewise (n_knots={best_pw['n_knots']})    : {best_pw['Price']:.4f}\")\n",
        "print(f\"  Kernel (bandwidth={best_kr['bandwidth']})     : {best_kr['Price']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tDZi-nQz7YoY",
      "metadata": {
        "id": "tDZi-nQz7YoY"
      },
      "source": [
        "# Task 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NWIcI2bR7aFW",
      "metadata": {
        "id": "NWIcI2bR7aFW"
      },
      "outputs": [],
      "source": [
        "# simulation\n",
        "\n",
        "def independent_pricing(exercise_policy, n_paths=100000):\n",
        "    ts = exercise_policy['ts']\n",
        "    K = exercise_policy['K']\n",
        "    r = exercise_policy['r']\n",
        "    regression_func = exercise_policy['regression_func']\n",
        "    regression_params = exercise_policy['regression_params']\n",
        "    models = exercise_policy['models']\n",
        "\n",
        "    new_paths = blackscholes_mc(ts, n_paths, S0, vol, r, q)\n",
        "\n",
        "    n_steps = len(ts)\n",
        "    payoff = np.maximum(K - new_paths[-1], 0)\n",
        "\n",
        "    for i in range(n_steps-2, 0, -1):\n",
        "        discount = np.exp(-r * (ts[i+1] - ts[i]))\n",
        "        payoff = payoff * discount\n",
        "\n",
        "        exercise_value = np.maximum(K - new_paths[i], 0)\n",
        "\n",
        "        model = models[i-1]\n",
        "\n",
        "        if model['type'] == 'polynomial':\n",
        "            cont_value = np.polyval(model['coeffs'], new_paths[i])\n",
        "        elif model['type'] == 'bs_basis':\n",
        "          tau = model['tau']\n",
        "          Z = blackscholes_price(K, tau, new_paths[i], model['vol'], r, model['q'], callput='put')\n",
        "          cont_value = model['beta'][0] + model['beta'][1] * Z\n",
        "        elif model['type'] == 'piecewise':\n",
        "            knots = model['knots']\n",
        "            coeffs_list = model['coeffs_list']\n",
        "            n_knots = model['n_knots']\n",
        "            segment = np.searchsorted(knots, new_paths[i]) - 1\n",
        "            segment = np.clip(segment, 0, n_knots-1)\n",
        "            cont_value = np.zeros(n_paths)\n",
        "            for j in range(n_knots):\n",
        "                mask = segment == j\n",
        "                if coeffs_list[j] is not None and np.sum(mask) > 0:\n",
        "                    cont_value[mask] = np.polyval(coeffs_list[j], new_paths[i][mask])\n",
        "        elif model['type'] == 'kernel':\n",
        "            distances = new_paths[i][:, np.newaxis] - model['X'][np.newaxis, :]\n",
        "            weights = np.exp(-0.5 * (distances / model['bandwidth'])**2)\n",
        "            weights /= weights.sum(axis=1, keepdims=True)\n",
        "            cont_value = weights @ model['Y']\n",
        "\n",
        "        exercise_mask = exercise_value > cont_value\n",
        "        payoff_new = payoff.copy()\n",
        "        payoff_new[exercise_mask] = exercise_value[exercise_mask]\n",
        "        payoff = payoff_new\n",
        "\n",
        "    price = np.mean(payoff * np.exp(-r * (ts[1] - ts[0])))\n",
        "\n",
        "    return price"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "z8Qi_49v_Ic6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8Qi_49v_Ic6",
        "outputId": "797aaa3d-16f0-4d2f-9dc7-720d031fb800"
      },
      "outputs": [],
      "source": [
        "# result for task2\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"TASK 2: INDEPENDENT MONTE CARLO PRICING (100,000 PATHS)\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nApplying learned exercise policies to independent simulation paths\\n\")\n",
        "\n",
        "print(f\"{'Method':<25} {'Task 1':>12} {'Task 2':>12} {'Difference':>12}\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "# 1. Polynomial\n",
        "price_task2_poly = independent_pricing(policy_poly, n_paths=100000)\n",
        "diff_poly = price_poly - price_task2_poly\n",
        "print(f\"{'Polynomial (deg=3)':<25} {price_poly:>12.4f} {price_task2_poly:>12.4f} {diff_poly:>12.4f}\")\n",
        "\n",
        "# 2. BS Basis\n",
        "price_task2_bs = independent_pricing(policy_bs, n_paths=100000)\n",
        "diff_bs = price_bs - price_task2_bs\n",
        "print(f\"{'BS Basis (vol=0.2)':<25} {price_bs:>12.4f} {price_task2_bs:>12.4f} {diff_bs:>12.4f}\")\n",
        "\n",
        "# 3. Piecewise\n",
        "_, policy_pw_final = ls_pricer(paths, K, r, ts, regression_piecewise, n_knots=best_pw['n_knots'])\n",
        "price_task2_pw = independent_pricing(policy_pw_final, n_paths=100000)\n",
        "diff_pw = best_pw['Price'] - price_task2_pw\n",
        "print(f\"{'Piecewise (n_knots=' + str(best_pw['n_knots']) + ')':<25} {best_pw['Price']:>12.4f} {price_task2_pw:>12.4f} {diff_pw:>12.4f}\")\n",
        "\n",
        "# 4. Kernel\n",
        "_, policy_kr_final = ls_pricer(paths, K, r, ts, regression_kernel, bandwidth=best_kr['bandwidth'])\n",
        "price_task2_kr = independent_pricing(policy_kr_final, n_paths=100000)\n",
        "diff_kr = best_kr['Price'] - price_task2_kr\n",
        "print(f\"{'Kernel (bandwidth=' + str(best_kr['bandwidth']) + ')':<25} {best_kr['Price']:>12.4f} {price_task2_kr:>12.4f} {diff_kr:>12.4f}\")\n",
        "\n",
        "print(\"=\"*70)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_P2dUMmF4RZG",
      "metadata": {
        "id": "_P2dUMmF4RZG"
      },
      "source": [
        "## Why Task 2 Provides a Lower Bound\n",
        "\n",
        "### Theoretical Foundation:\n",
        "\n",
        "The Longstaff-Schwartz algorithm learns an approximate exercise policy from a finite training sample. Task 2 estimates provide a lower bound due to the fundamental distinction between in-sample and out-of-sample evaluation.\n",
        "\n",
        "**Training Bias (Task 1):**\n",
        "The exercise policy is learned by optimizing on the training paths. When we evaluate this policy on the same paths used for training, we obtain an overly optimistic estimate. This is analogous to overfitting in machine learning: the policy is tailored to the specific training sample, resulting in inflated performance metrics.\n",
        "\n",
        "**Unbiased Evaluation (Task 2):**\n",
        "Task 2 applies the learned policy to independent test paths that were not used during training. Since these paths are statistically independent from the training data, the evaluation is unbiased. The policy cannot exploit the specific characteristics of these new paths, yielding a realistic assessment of its true performance.\n",
        "\n",
        "**Key Inequality:**\n",
        "The expected in-sample estimate (Task 1) is greater than or equal to the true value of the learned policy, which equals the expected out-of-sample estimate (Task 2). This relationship holds because:\n",
        "1. In-sample evaluation suffers from positive bias due to optimization on the same data\n",
        "2. Out-of-sample evaluation on independent data provides an unbiased estimate\n",
        "3. Therefore, in-sample estimates systematically exceed out-of-sample estimates\n",
        "\n",
        "### Empirical Confirmation:\n",
        "\n",
        "Our results demonstrate Task 2 ≤ Task 1 consistently across all four regression methods, confirming the theoretical prediction that out-of-sample evaluation provides lower (and more realistic) price estimates than in-sample evaluation."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
